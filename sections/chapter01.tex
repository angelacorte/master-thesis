%! Author = angela
%! Date = 24/01/24
% !TeX root = ../thesis-main.tex

%----------------------------------------------------------------------------------------
\chapter{Introduction}
\label{ch:introduction}
%----------------------------------------------------------------------------------------
This chapter introduces the background of this thesis, including our position, main objectives,
and the current state of the art.

\section{Context}
\label{sec:context}

Computing devices are becoming cheaper and \emph{ubiquitous}, with objects being increasingly equipped with
computational capabilities and interconnected to form the \ac{iot}, increasing the complexity of
distributed systems.
It is now common for individuals to own multiple computing devices of varying types, resulting in technology becoming
more integrated into daily activities.
Inside those kinds of systems, different software components, and not necessarily one for each device, interact with each
others building innovative services of cyber-physical nature, capable of creating a fast bridge between the real and
the digital world.

Managing a single device in a distributed system can be challenging for several reasons, as:
    i) \textbf{scalability}, as the number of devices increases, managing each device individually becomes increasingly complex;
    ii) \textbf{resource constraints}, individual devices may have limited computational power, memory, and energy resources,
        making it challenging to perform complex tasks efficiently;
    iii) \textbf{heterogeneity}, devices in \ac{iot} systems often vary in terms of hardware capabilities, communication
        protocols, and software configurations, resulting in challenging management;
    iv) \textbf{context awareness}, single devices may have limited awareness of the broader context or environment in
        which they operate, leading to suboptimal decision-making and interactions.

Transitioning from a device-centric to an aggregate-centric approach can lead to several advantages:
    i) \textbf{distributed intelligence}, leveraging the collective capabilities of multiple devices enables distributed
        intelligence, where the system's intelligence emerges from interactions and collaboration among devices;
    ii) \textbf{resource pooling}, across multiple devices results in more efficient use of resources, such as computational
        power, memory, and energy;
    iii) \textbf{adaptability}, collective-centric approaches enable systems to adapt dynamically to changes in the
        environment or system requirements; devices can collaborate to self-organise, self-adapt, and self-optimise
        based on contextual information;
    iv) \textbf{robustness}, distributing computation and decision-making across multiple devices enhances system
        robustness and resilience to individual device failures or disruptions.

From an engineering perspective, the construction of \ac{iot} applications differs substantially from that of traditional
software, especially when a particular service, to be realised, requires the coordination of devices of different nature.
Hence, the need to engineer and coordinate the operations in such systems, one way is to program and operate in terms of
\emph{aggregates} of devices, or \ac{cas}, rather than manage each single device.
In fact, the coordination of macroscopic behaviour in collective systems through a single program is a form of
~\emph{macroprogramming}.
However, this approach presents some primary challenges such as ensuring resilience, efficiency and privacy.

\paragraph{Collective Adaptive Systems}
\label{par:collective-adaptive-systems}
\ac{cas} are systems composed of multiple autonomous entities, such as devices, sensors, and actuators, that interact to
achieve a common goal \cite{10.1145/2800835.2809508}.
These systems are known for their ability to adjust to changes in their environment, system requirements, or operational conditions.

\ac{cas} are frequently used in \ac{iot} and \ac{cps} applications, where devices collaborate to achieve a common goal,
such as monitoring and controlling a physical environment or providing a service to users.
The coordination of devices in \ac{cas} can be challenging due to device heterogeneity, resource constraints, and the
dynamic environment.

To promote collective behaviours, macroprogramming is used, leveraging its high-level abstractions and constructs to
facilitate global coordination, decentralised control, and adaptability in complex systems.

\paragraph{Macroprogramming}
The term \emph{macroprogramming} ~\cite{10.1145/3579353} refers to the concept of expressing the macroscopic behaviour of a system through a single
program, usually leveraging macro-level abstractions.
This paradigm is driven by the need to capture \emph{system-level behaviour} while abstracting the behaviour and interaction
of the individual components involved.
Macroprogramming approaches have been suggested to simplify the development of systems involving numerous interconnected
sensors, actuators, and smart devices; they can be applied in contexts like \ac{iot} and \ac{cps}.

Macroprogramming abstractions can promote collective behaviour properties, such as self-organising or self-configuring in
the context of \ac{cas}.
By declaring tasks within a specific spatio-temporal region, systems can self-organise and effectively perform the task
at hand, allowing for dynamic adaptation to the current deployment and spatial positions of the components involved.

\paragraph{Self-Organisation}
Coordination modes are based on the notion that interactions among multiple independent and autonomous software systems
can be designed as a space orthogonal to pure computation.
This idea can be reified into a concept of shared data space, enabling so-called \emph{generative communication}.

Over the course of time, different approaches have been created, such as \emph{Linda} ~\cite{10.1145/2363.2433} and \emph{Mars} ~\cite{865084},
suggesting innovative techniques for programming systems with devices of different nature focusing on the coordination
of centralised local components, but not on the distribution of the systems.
The main problems that can be encountered in distributed systems are dealing with
    \emph{(i)} openness, as unexpected environment changes,
    \emph{(ii)} large scale of agents and coordination abstractions to be managed,
    \emph{(iii)} intrinsic adaptiveness, such as the ability to intercept relevant events and react to them, guaranteeing
        the resilience of the system.

The challenges necessitate a \emph{self-organising coordination} approach, wherein coordination abstractions solely
manage logical interactions.
This ensures the emergence of global and robust patterns of correct coordination behaviour.

\subsection{Computational Fields}
\label{subsec:computational-fields}

\paragraph{Field-Based Coordination}
To facilitate self-organisation patterns of agents in complex environments, the concept of \emph{coordination field}
has been introduced.
This abstraction serves as a navigational tool for agents over the actual environment.

In this context, the tuple-based middleware \emph{TOTA} (Tuples On The Air) ~\cite{10.1145/1538942.1538945}
has been suggested to support field-based coordination for pervasive-computing applications.
Initially, each field of the tuple in the system was assigned a name, along with a formula that supports the
if-then-else construct and includes arithmetic and boolean operators to specify the field's behaviour over time.
Secondly, it was introduced an operator in the tuple space responsible for applying formulas using contextual information.

Somewhat independently of the challenge of identifying appropriate coordination models for distributed and situated systems,
several studies have tackled analogous issues in the broader endeavour of constructing distributed intelligent systems.
This involves promoting higher abstractions of spatial collective adaptive systems.

\paragraph{Field Calculus}
Among the studies such as for managing space-time computing models for the manipulation of distributed data structures,
the notion of \emph{computational fields} were proposed ~\cite{VIROLI2019100486}.
Consequently, the ~\ac{fc} has been proposed as a foundational model for the coordination of computational
devices spread in physical environments, also known as \emph{aggregate computing}.

~\ac{fc} was introduced as minimal core calculus with the aim of capturing the fundaments that make use of computational
fields: functions over and with fields, their evolution over time and the construction of field of values from neighbours.

The main concept of \ac{fc} is to specify the aggregate system behaviour of a network of devices, where devices that can
directly communicate with each other are indicated through a dynamic network relation.
An example of its application is within a sensor network with a range of a broadcast communication.

The behaviour is applied through a functional composition of operators that manipulate the computational fields,
called specification, that can be interpreted locally or globally.
A local specification can describe a computation on an individual device executed in asynchronous ``computation rounds'',
including sending or receiving messages from neighbours, getting information from sensors and computing the local value of the field.
Each round is divided in three phases:
    i) \emph{context building}, where the device collects information from the environment and from the messages received
        from neighbours, and aggregates them to build a local context;
    ii) \emph{program execution}, each device executes a local program on the context;
    iii) \emph{export sharing}, the device sends messages to its neighbours, containing the results of the computation.

In the global view, a field calculus expression specifies a mapping associating each computation round of each device to
the value that it assumes at that space-time event.

This dual nature inherently facilitates the alignment of individual device behaviour with the overarching global behaviour
of the entire network of devices.


\paragraph{Syntax of field calculus}
\label{par:syntax-of-field-calculus}

The \emph{field calculus} is based on a minimal set of operators:
\begin{itemize}
    \item \emph{Stateful field evolution}: the expression $rep(e_1)\{(x) \rightarrow e_2\}$ describes a field evolving in time.
        $e_1$ represents the initial field value, the function $(x) \rightarrow e_2$ declares how the field changes
        at each execution;
    \item \emph{Neighbour interaction}: the expression $nbr\{e\}$ builds a neighbouring field, a view of the field
        values in the surroundings of each device where neighbours are mapped to their evaluations of \texttt{e};
    \item \emph{Domain partitioning}: the expression $if(e_0)\ \{e_1\}\ \{e_2\}$ splits the computational field into
        two non-communicating zones hosting isolated computations: $e_1$ where  $e_0$ is \texttt{true} and
        $e_2$ where  $e_0$ is \texttt{false}
\end{itemize}

\begin{lstlisting}[label={lst:field-calculus-program}, language=fieldCalculus, caption={The \texttt{rep} construct
establishes an initial distance estimate \textbf{d} set to infinity, which then diminishes based on two conditions.
If the source variable is \textbf{true}, indicating that the device is presently a \textbf{source}, its distance to
itself is considered zero.
Alternatively, if the device is not a \textbf{source}, the distance estimate is determined using the triangle inequality.
This involves computing the minimum value obtained by adding the distance to each neighbour (using the \texttt{nbrRange}
built-in function) to the neighbour field value (accessed via the $\texttt{nbr{d}}$ notation).
The \texttt{mux} function ensures that all arguments are evaluated prior to selection.}]
def mux(b, x, y) { if (b) {x} {y} }
def distanceTo(source) {
    rep(infinity){ (d) =>
        mux(source, 0, minHood(nbr{d} + nbrRange())
    }
}
\end{lstlisting}

In ~\Cref{lst:field-calculus-program} is shown a simple example of a field calculus program; it calculates the distance
from a source node in a network.
To implement more elaborated computations, it becomes necessary to combine the \texttt{rep} and \texttt{nbr} constructs.
Their combination allows recreating a behaviour that evolves both in time and space: with \texttt{nbr} information is
exchanged with neighbours, while \texttt{rep} takes care of the evolution of its own field.
However, the joint use turned out that contained a hidden delay, identified and explained in \cite{fieldc}.

To overcome the problem in the interaction between the two constructs, it has been proposed a new one:
$share(e_1)\{(x) \rightarrow e_2\}$.
This construct differs from \texttt{rep} and \texttt{nbr} combination in the way that the variable \texttt{x} is
interpreted ad each round, that is identified as a \emph{neighbouring field} rather than a value.
In this case, $e_2$ is responsible for processing the neighbouring field into a local value shared with the
neighbours at the end of the evaluation.
Therefore, the \texttt{share} improves the communication speed.

The example proposed in ~\Cref{lst:field-calculus-program} can be rewritten using the \texttt{share} construct as in ~\Cref{lst:field-calculus-program-share}.
\begin{lstlisting}[label={lst:field-calculus-program-share}, language=fieldCalculus, caption={The \texttt{share} construct
is used to calculate the distance from a source node in a network.}]
def distanceTo(source) {
    share(infinity){ (d) =>
        mux(source, 0, minHood(d + nbrRange())
    }
}
\end{lstlisting}

\paragraph{Alignment}
The semantics of this language is defined as compositional and messages are exchanged thanks to \texttt{nbr}, with each 
message from a neighbour being automatically matched to a specific \texttt{nbr} construct, determined by a process called \emph{alignment}.
Each construct generates an ``export'', a data value intended to be sent to the neighbours, labelled with the coordinates
of the node in the evaluation tree up to that construct.
These exports are gathered into a message to broadcast to the neighbours that can be modelled as a value tree:
an ordered tree of values obtained during the evaluation of each sub-expression of the program.

The \emph{alignment} mechanism ensures that each construct of a device is matched with the corresponding construct of
the neighbours, following an identical path in the evaluation tree.

\subsection{Aggregate Computing}
\label{subsec:aggregate-computing}

Aggregate programming elaborates a layered architecture that aims to simplify the design, creation and maintenance of
distributed systems \cite{CASADEI2019252}.

Through this methodology, the fundamental unit of computation shifts from an individual device to a collaborative
ensemble of devices.
It elaborates a layered architecture that aims to simplify the design, creation and maintenance of complex distributed
systems.

Moreover, aggregate programming provides mechanisms for robust and adaptive coordination through simple programming APIs
that implicitly guarantee safety and resilience.
This framework is useful in large-scale scenarios, where there is insufficient fixed network infrastructure, as seen in
situations like crowd management during large public events.

In various environments, interactions between wearable devices such as smartphones can support different kinds of services,
including crowd detection, crowd-aware navigation or dispersal advice.

~\ac{ac} is a paradigm and engineering approach for the compositional development of self-adaptive ~\ac{iot} services
from a global perspective ~\cite{10.1145/3579353}.

It has been developed with the core idea of functionality composing collective behaviours to achieve effective and resilient
complex behaviours in dynamic networks.
It views a given environment as a whole programmable entity whose parts collaboratively produce and consume services
across space and time.
~\ac{ac} is based on the principles of~\ac{fc} that is a functional programming model used to specify
and compose collective behaviours with formally equivalent local and aggregate semantics.

The concept of \emph{computational fields} can be viewed as a distributed data structure,
with the aim of conceptually mapping each device to a value produced in a program, considering both
space and time.
Therefore, its structure supports the specification, analysis, simulation and runtime execution of \emph{collective}
or \emph{aggregate} services, independently of the specific~\ac{iot} architecture.

This paradigm has three key traits that characterise it:
    \emph{(i)} \emph{Global stance with global-to-local mapping}, where the target of system design is the entire distributed
        \ac{iot} ecosystem,
    \emph{(ii)} \emph{Behaviour compositionality}, whereby a rich collective service can be described in terms of the functional
        composition of simpler collective services, and
    \emph{(iii)} \emph{Abstraction}, by which aggregate services enable adaptivity at different levels by abstracting from low-level
        issues and details.
These attributes are crucial both in the design phase, where intricate solutions can frequently be articulated concisely
and declaratively, and in the operational phase, where considerable flexibility is granted to the devops team and the
platform regarding execution specifics and deployment strategies.
The overall stack of the aggregate computing is shown in ~\Cref{fig:ac-stack}.

\begin{figure}
    \centering
    \includegraphics[width=.7\linewidth]{figures/aggregate-programming-stack}
    \caption{The aggregrete programming stack \cite{7274429}.}
    \label{fig:ac-stack}
\end{figure}

\paragraph{Software platforms}
~\ac{ac} is designed to address many application scenarios, typically characterised by inherent distribution, heterogeneity,
mobility and a lack of stable infrastructure.
There are various strategies by which an~\ac{ac} system can run, contingent upon the selected and implemented
communication methodologies.

Programs can be executed within a fully distributed peer-to-peer environment, where end devices communicate directly
with peer neighbours, and each independently runs its fragment of aggregate logic.

On the opposite side, there are entirely centralised solutions, where end devices function solely as manager for sensors
and actuators, forwarding perceptions upstream to one or more servers.
These servers perform computations on behalf of the devices and subsequently transmit actuation data downstream.
Thanks to this flexibility of its applications,~\ac{ac} has the potential to facilitate the creation of a more systematic
spectrum for transitioning between cloud and distributed systems.
This approach also embraces the emerging domains of Edge ~\cite{8795355} and Fog Computing ~\cite{bdcc2020010}.

\paragraph{Aggregate computing in adaptive \ac{iot} Services}
Thanks to its features, \emph{aggregate computing} is well suited for the development of \emph{Opportunistic \ac{iot}
Services}, supporting the properties:
\begin{itemize}
    \item \emph{Dynamicity}: the direct support for opportunistic service activation and evolution is achieved through
        code mobility and constructs that define dynamic domains of computations dependent on space and time;
    \item \emph{Context-awareness}: aggregate programs utilize sensors, communication driven by neighborhood interactions,
        and iterative execution to consistently evolve the set of local contexts.
        This evolution forms the basis for the unfolding of computation and coordination logic;
    \item \emph{Co-location}: as a natural method to define the concept of neighbourhood, relies on a physical space basis.
        \ac{ac} inherently incorporates locality (both in space/time and purpose) to organise interactions and activities;
    \item \emph{Transience}: \ac{ac} provides constructs that directly supports the execution of distributed services
        based on time and context awareness.
\end{itemize}

\paragraph{Computational model}
There are some concepts and relationships included in the \emph{aggregate computing} context:
\begin{itemize}
    \item \emph{Aggregate program}: an executable representation of specific aggregate logic that defines a collective behaviour;
    \item \emph{Aggregate system}: a set of interconnected nodes or devices that support the collective execution of aggregate programs;
    \item \emph{Aggregate application}: a specific aggregate logic operating on a designated aggregate system, aimed at
        solving particular problems in a specific context;
    \item \emph{Node}: also referred to as \emph{device}, it represents an individual \ac{ac}-enabled entity, potentially
        equipped with sensors and actuators;
    \item \emph{Neighbourhood}: the logical or physical set of nodes that can be directly contacted by a given node;
    \item \emph{Global or local sensor}: a source for global or local information;
    \item \emph{Global or local actuator}: a global or local actionable device for environment-directed actions;
    \item \emph{Global or local computational environment}: anything that is detectable and subject to action through the
        use of global (or local) sensors and actuators
        This also includes the shared functionalities offered by the platform.
\end{itemize}

The networked devices inside an aggregate system compute and communicate at asynchronous rounds of execution.
Each round, each device executes the global aggregate program according to the local semantics; then it updates its internal
state and lastly generates the data for the external communication.

The round is performed by taking into account the computational context created by the previous state, sensor data and
messages from neighbouring devices.
After the execution of the round, result data are made available to neighbours and eventually instructed actuations are
locally executed.
The system can continuously react to changes by repeatedly executing rounds, allowing for self-adaptation to contextual changes.

\paragraph{Models alignment}
Due to the high-level and platform-independent metamodels of \ac{iot} and \ac{ac} systems, each with different goals or
abstraction levels, it is necessary to align the two metamodels.
This ensures that their unique focus is taken into account.

There are some main differences between the two metamodels:
\begin{itemize}
    \item the concept of device is different, for \ac{ac} is logical and is not the same as a device component of a Smart Object;
    \item although ensembles of Smart Objects are conceptualised as firs-class concept in \ac{ac}, they are not explicitly
        represented in the \ac{iot} system metamodel;
    \item the concept of neighbourhood in \ac{ac} regulates local, contextual communication among its devices.
        However, this concept cannot be explicitly mapped to \ac{iot} system concepts because device-to-device relationships
        are abstracted away from the metamodel.
\end{itemize}

\subsection{XC}
\label{subsec:xc}
\xc{} is an experimental programming language design to develop \emph{homogeneous} distributed systems.
Those kinds of systems consist of similar devices that communicate to neighbours and execute the same program.
The aim of this experimental language is to push the abstraction boundaries farther than actual existing approaches.

Many issues can arise in distributed systems, like concurrency, remote communication, asynchronous execution, message
loss, and device failures.
These kinds of problems must be taken into account when designing a programming language for such systems.
Some of the possible applications of this approach may be crowd management by handled devices~\cite{7274429},
gossip-based data aggregation~\cite{10.1145/1082469.1082470}, task allocation in robot swarms \cite{swarms1,1420661},
and coordination of enterprise servers \cite{7306601}.

The homogeneity in large-scale systems also arises when each device executes a program from a predefined set, reflecting
a homogeneous configuration featuring a single program with an initial branch.

\paragraph{System model}
Devices that can send or receive messages are called \emph{neighbours}, and they can change dynamically to model network
delays, failures or spatial movements.

Based on existing homogeneous systems, the device behaviour has been abstracted through a notion of \emph{execution round},
in which a device independently executes an \xc{} program and sends the resulting messages to its neighbours.
Referring to \emph{macroprogramming}, each device's behaviour in the network is developed as a single program, with no
assumption of when an execution round will occur, meaning that they are entirely asynchronous.

Messages are handled queueing up in a buffer; when a device executes its \xc{} program, it processes the received
messages producing others to send to neighbours, that in turn will process their messages.

\begin{figure}
    \centering
    \includegraphics[width=.5\linewidth]{figures/xc-system-model}
    \caption{This image shows the devices' behaviour in \xc{} where each $\delta_n$ is a device, $\epsilon_n$ is a computation round
        and the arrows represent the messages sent between devices.
        The device $\delta_2$ executes two computation rounds $\epsilon_1$ and $\epsilon_2$.
        After the computation, $\delta_2$ sends a message to $\delta_1$ and $\delta_3$.
        It can occur that a device $\delta_1$ executes multiple rounds before $\delta_2$ executes its own, in that case $\delta_2$ will
        only see the last-received message from the device $\delta_1$; newly received messages will overwrite the older ones.
        Grey arrows are messages lost never received.
    }
    \label{fig:xc-system-model}
\end{figure}

It can occur that a device executes multiple rounds before a neighbour executes its own, in that case the neighbour will
only see the last received message from the first device; newly received messages will overwrite the older ones.
Messages can persist across rounds; they are not removed from the buffer after they have been read unless they expire.
The devices for which a message is available in a certain round are considered the \emph{neighbours} for that round.

\paragraph{Data types}
\label{par:data-types}
\xc{} features two kinds of values:
    \emph{(i)} \emph{local values (l)}, that include traditional types, and
    \emph{(ii)} \emph{neighbouring values (nvalues)}, a map from the device identifier to their local values, used to describe
        the set of values received from and sent to neighbours.
In highly decoupled networks, it can occur that not all devices will produce a value, for this reason it will be used
a default value.

Different types of operations can be applied to \emph{nvalues}, where the function passed is repeatedly applied to
neighbour's values in a field $\underline{w}$, excluding the self-value.
A \emph{local value} can be also converted to a \emph{nvalue} using the default value for every device.

\paragraph{Communication in XC}
\label{par:communication-in-xc}

\xc{} is based on a key communication primitive:\\ $exchange(e_i,\ (\underline{n}) \rightarrow \ \texttt{return} \ e_r \ \texttt{send} \ e_s)$
which is evaluated as follows.
    \emph{(i)} the device computes the local value from the initial value $e_i$.
    \emph{(ii)} the variable $\underline{n}$ gets substituted with the computed nvalues $\underline{w}$ of the received messages, eventually
        using the local value as default, the exchange returns the computed value $v_r$ from $e_r$.
    \emph{(iii)} $e_s$ evaluates to a nvalue $\underline{w}_s$ consisting of local values to be sent to neighbours,
        that will take their corresponding value from $\underline{w}_s$ and use it for the execution of their next round.

A common pattern that can be used is to access neighbour's values through the use of the \texttt{exchange} function, as follows.\\
$nbr(e_i,\ e_s) = exchange(e_i, (\underline{n}) \rightarrow \texttt{return} \ \underline{n} \ \texttt{send} \ e_s)$,
which means that the value of expression $e_s$ is sent to neighbours and returns the received values gathered as
$\underline{n}$ with its default, thus providing a view on neighbours' values $e_s$.
Often the expressions $e_r$ and $e_s$ coincide, in this case, the \texttt{exchange} function is
$exchange(e_i, (\underline{n}) \rightarrow \texttt{retsend} \ e)$.

The crucial aspect of the \xc{} expressivity is that \texttt{exchange} can send a different value to each neighbour,
allowing custom interaction through them.

\paragraph{Conditionals}
\label{par:conditionals}
\xc{} supports conditional expressions, like $if\ (cond)\ \{e_1\}\ else\ \{e_2\}$.
An exchange aligns only across the devices that take the same branch; thus, it evaluates only aligned sub-expressions.
This means that a network can be split by a conditional expression into two non-communicating subnetworks, each
evaluating a different branch without cross-communication.

\paragraph{Fault tolerance}
\xc{} programs are resilient to failures: in case a node gets disconnected or messages get lost, the failed node won't
show up among the neighbours of a given node in the next alignment.
The logic of \emph{exchange} is set to let neighbours' messages collectively operate, in order to make no assumptions
on their number or identity.
It is crucial to highlight that XC does not inherently offer assurances regarding fault tolerance.
As a Turing-complete language, the capability to program non-resilient behaviour is inevitably present.

\subsection{Collektive}
\label{subsec:collektive}
\emph{Collektive} is a minimal \ac{dsl} for aggregate programming, designed to simplify the development of distributed systems
by providing high-level abstractions for collective coordination and communication.
It provides the means to specify the collective behaviour of a network of devices, where devices can directly communicate
with each other and execute the same program.
\emph{Collektive} is based on the principles of \ac{ac}, and it is designed to be used in the context of \ac{iot} applications.
The language is designed to be easy to use, and to provide a high-level of expressiveness, while at the same time being
efficient and scalable.

\section{Motivations}
\label{sec:motivations}

In this section, the motivations for extending the existing \ac{dsl} \emph{Collektive} by applying the concepts of \xc{}
to aggregate programming constructs will be illustrated, the objectives that are intended to be achieved and the benefits
that are expected to be obtained.

From an engineering perspective, the construction of \ac{iot} applications differs substantially from that of traditional
software, especially when a particular service, to be realised, requires the coordination of devices of different nature.

\paragraph{Challenges and innovations}
Over the course of time, different approaches have been proposed to program these systems, such as TOTA, SAPERE \cite{ZAMBONELLI2011197},
Aggregate Computing \cite{Beal2016}, Linda \cite{10.1145/2363.2433}, MARS \cite{865084} and others.

The most successful solution at the moment involves the use of Cloud Computing (see ~\Cref{fig:cloud-edge-continuum}),
which provides virtualized resources on a large scale, but presents limitations in terms of latency (due to the physical
distance between machines) and scalability (due to centralisation) despite the significant improvement compared to traditional
approaches.
Cloud providers offer elastic scaling capabilities that allow organizations to dynamically adjust resources based on demand,
minimizing the impact of scalability limitations and optimizing cost-efficiency.

Despite the scalability advantages of cloud computing, there are still scenarios where it may not be sufficient to meet
the requirements of certain applications and workloads.
For this reason, Edge Computing and Fog Computing have recently emerged, aiming to bring resources closer to the outer
edge of the network, where interoperability problems between devices and complexity in managing distributed resources increase.

The design of applications capable of operating indistinctly on the cloud, on the edge, or even on a mesh network
(in fact, on a computational continuum that goes from the edge to the cloud) can benefit from unconventional approaches,
such as Aggregate Computing.

\begin{figure}
    \centering
    \includegraphics[width=.5\linewidth]{figures/edge-cloud}
    \caption{This figure shows the continuum of computing from the edge to the cloud, highliting the edge-cloud verticality
    and the heterogeneity of devices.}
    \label{fig:cloud-edge-continuum}
\end{figure}

\subsection{Heterogeneity limitations}
\label{subsec:heterogeneity-limitations}

One of the limitations of current collective programming approaches is the management of heterogeneity.
In fact, the system assumes that there is a certain uniformity of capabilities along the continuum, or that it is possible
to abstract it in some way (see, for example, the ``pulverization'' approach ~\cite{fi12110203}).

However, when the system includes devices whose nature is profoundly different (imagine, for example, a system where both
well-equipped servers and tiny wearable or implanted devices with very moderate computing capabilities participate, as
shown in ~\Cref{fig:smart-network-objects}), finer mechanisms are needed.
Such mechanisms can be the combination of adaptive strategies, resource management techniques, and the use of programming
languages that can abstract the heterogeneity of devices.

A somewhat analogous problem appears in functional programming when modelling effects, and recent proposals aim to capture
them in the form of capabilities.

\begin{figure} [!ht]
    \centering
    \includegraphics[width=.8\linewidth]{figures/smart-network-objects}
    \caption{Our world is increasingly populated with a wide range of computing devices, embedded in our environment
    and with many opportunities for local and even location-independent interactions on fixed network infrastructures \cite{7274429}.}
    \label{fig:smart-network-objects}
\end{figure}

\subsection{Goal}
\label{subsec:goal}
The goal of this thesis is to extend the existing \ac{dsl} \emph{Collektive} by applying the concepts of \xc{} to
aggregate programming constructs, thus seeking to improve its performance in order to make this \ac{dsl} competitive
against existing approaches.
Furthermore, the aim is to create an incarnation of this \ac{dsl} in such a way that it can execute simulations through
Alchemist ~\cite{10.1007/978-3-030-78198-9_10}, which serves as a meta-simulator primarily tailored for simulating
intricate distributed systems across a diverse range of scenarios.
These scenarios include swarm robotics ~\cite{aguzzi2024macroswarm}, large-scale sensor networks ~\cite{9927406}, crowd
simulation~\cite{7274429}, path planning, and even the morphogenesis of multi-cellular systems.

It is necessary to rely on technologies and languages that can run on any device.
\ac{kmp} will be used, which allows developers to write code that can be compiled for multiple targets,
including JVM (ideal for server environments), Javascript (browser), Android, iOS (including watchOS and tvOS), and native versions
(for Windows, MacOS, and Linux, both for x86 and ARM CPUs).

\paragraph{Impact}
The creation of a new programming language for aggregate computing is expected to have a substantial impact on the
development of distributed systems, especially in the \ac{iot} and \ac{cps} domains.
The new language will allow developers to write programs that can be executed on any device, regardless of its nature,
and will be able to communicate with other devices in the network, thus simplifying the development of complex systems.

In addition, the new language is expected to have an impact on the performance of distributed systems, as the constructs
of \xc{} have been designed to ensure greater efficiency in the execution of distributed programs.

\section{State of Art}
\label{sec:state-of-art}

In this section, it will be presented the state of the art in the field of aggregate computing, focusing on the main existing
frameworks and languages and their limitations.

Still, in terms of portability to heterogeneous systems, there are currently several software programs that implement the
semantics of aggregate programming derived from field calculus, but they are not interoperable with each other.

\subsection{ScaFi}
\label{subsec:scafi}

\emph{ScaFi (Scala Field)} is a Scala-based framework for aggregate programming\\ ~\cite{CASADEI2022101248}.
It provides a \ac{dsl}, libraries, a simulation environment with a GUI, integrated with the
Alchemist simulator, and an actor-based runtime for the development of aggregate computing-based systems.
\emph{ScaFi}'s core is based on a variant of the \emph{field calculus} called \emph{F ScaFi} ~\cite{10.1007/978-3-030-61470-6_21},
which peculiarity is to handle standard values to provide a simplified setting for \ac{dsl} embedding.

This is achieved by introducing a notion of ``computation against neighbours'', meaning that is a computation whose
output depends on the most recent values received from neighbours.

\begin{figure}
    \centering
    \includegraphics[width=.7\linewidth]{figures/scafi-structure}
    \caption{High-level architecture of the ScaFi toolkit.}
    \label{fig:scafi-structure}
\end{figure}

The architecture of \emph{ScaFi} consists of various modules, as seen in ~\Cref{fig:scafi-structure}.
The \ac{dsl} and standard library of reusable functions are implemented in the \texttt{scafi-
core} module; meanwhile, the modules \texttt{scafi-simulator} and \texttt{scafi-simulator-
gui} provide a simulation
environment of aggregate systems with a graphical user interface.

The main applications of \emph{ScaFi} are in the development of swarm systems ~\cite{10336236}, crowd management, wireless sensor network (WSN) ~\cite{9935036}
and smart city applications.

\emph{ScaFi} is capable of running aggregate programs on the \ac{jvm} and also on web browser thanks
to the \emph{ScaFi Web} tool ~\cite{10.1007/978-3-030-78142-2_18}, which allows the rapid prototyping of aggregate programs.
On the other hand, it does not provide an aggregate standard library in the public version, neither supports to
different advanced mechanisms.
Furthermore, it is based on Scala 2, which means that it needs a review to be updated to Scala 3.

Since \emph{ScaFi} only supports \ac{jvm} and web-based applications, it is not well-suited for the development of complex distributed systems.
devices and communication technologies, such as thin devices that do not support \ac{jvm}, which limits the heterogeneity of
devices that can be used in the system.

\subsection{Protelis}
\label{subsec:protelis}
\emph{Protelis} ~\cite{protelis} is a functional programming language that implements a higher-order version of the \emph{field calculus},
exposed through a C-like syntax, enabling the construction of widely reusable components of aggregate systems.
It also provides various domain-specific APIs that are interoperable with Java.
\emph{Protelis} has been developed since no foundational API for resilient, situated and distributed systems can be found
in the Java ecosystem.
It offers an implementation for the interoperability with the \emph{Alchemist} simulator, where it can be seen its
practical use in the development of aggregate systems.

\begin{figure}
    \centering
    \includegraphics[width=.5\linewidth]{figures/protelis-structure}
    \caption{The abstract architecture of Protelis.}
    \label{fig:protelis-structure}
\end{figure}

As seen in the \emph{Protelis} architecture (~\Cref{fig:protelis-structure}), an interpreter executes a pre-parsed program at regular intervals,
that communicates with other devices and draws contextual information from the environment.
This is instantiated by specifying when the executions occur, how the devices communicate and how the environment is
represented.

A key reason for this choice is that Java is highly portable across systems and devices.
Another important reason is that Java's reflection mechanisms make it easy to import a large number of useful libraries
and APIs for use in Protelis.

It is based on \emph{Xtext}, a framework for the development of domain-specific languages, which provides a set of tools
and libraries for the development.
For this reason necessary requires a \ac{jvm} to run, which limits the heterogeneity of devices
that can be used in the system.

\subsection{FCPP}
\label{subsec:fcpp}
\emph{FCPP} ~\cite{9196401} is an implementation of the \emph{Field Calculus} as a C++ library, with tools for simulations of distributed systems.
This library is built as a component-based system ~\Cref{fig:fcpp-structure}, with the aim of being easily extensible and reusable in different contexts.

It has a performance-oriented implementation based on compile-time optimisations, and it is designed to support
simulated systems executed in parallel or self-organising cloud application.

\begin{figure}
    \centering
    \includegraphics[width=.8\linewidth]{figures/fcpp-structure}
    \caption{The Software architecture of FCPP represented as three main layers.}
    \label{fig:fcpp-structure}
\end{figure}

Being implemented in C++, allows \emph{FCPP} to be used in a wide range of devices, including embedded systems and
microcontrollers, for which a C++ compiler is available.
Although \emph{FCPP} is designed as a flexible and easily extensible platform, its currently supported range of features
is more limited than \emph{Alchemist}'s.

It allows running aggregate programs on low computational capacity devices.
However, its syntax is less ergonomic compared to other languages, making it unlikely to reach a mainstream developer audience.

\paragraph{Final considerations}
Those three illustrated frameworks have more or less the same expressive power, with few notable differences.
The main differences among them are between \emph{ScaFi} and \emph{FCPP}, that are \emph{internal} \ac{dsl} implemented in Scala
and C++, and \emph{Protelis} that is an \emph{external} \emph{dsl}, interpreted in the \ac{jvm}.

Considering their syntax, \emph{ScaFi} and \emph{Protelis} partially imitate the abstraction level of the \emph{field calculus},
being bound by the specific syntactic constraints of their host languages.
Whereas, \emph{Protelis}' syntax is more neat and specifically designed for field computation.

However, the more complex syntax of \emph{Scafi} and \emph{FCPP} may prove easier to learn for programmers already familiar with Scala and C++.