%! Author = angela
%! Date = 24/01/24
% !TeX root = ../thesis-main.tex

\chapter{Validation}
\label{ch:validation}
This chapter describes the validation process of the new \ac{dsl} implementation and incarnation.
Validating the hypotheses is a fundamental step for the correct evaluation of the work done.
It is divided into testing and performance comparison, which are the two main aspects of this validation process.
By comparing the performance of the new implementation with the original one, it is possible to understand if the
introduction of the new features has led to an improvement in the performance of the system.

\section{Tests}
\label{sec:tests}
The testing phase is instrumental in affirming the integrity and functionality of the \ac{dsl} codebase developed for this thesis.
Tests serve as a critical mechanism for verifying the behaviour of the DSL across various scenarios, detecting potential bugs,
and validating adherence to specifications.

Since the \ac{dsl} is designed to be multiplatform, tests are written to ensure that the codebase is compatible with
different platforms and the results across platforms must be consistent.

To achieve this, Kotlin offers \emph{Multiplatform Extensions}, which allows the testing of the same codebase across
different platforms, such as \emph{JVM}, \emph{JS}, and \emph{Native}, just by adding needed extensions in the \texttt{build.gradle} file.
%sono i seguenti
The targets chosen for the testing are the following:
\begin{itemize}
    \item Linux x64 and ARM64;
    \item Windows x64(MinGW);
    \item MacOS x64 and ARM64;
    \item IOS x64 and (simulator) ARM64;
    \item WatchOS x64 and (simulator) ARM64;
    \item TvOS x64 and (simulator) ARM64;
\end{itemize}

Those were chosen to cover the most common platforms and to ensure that the \ac{dsl} is compatible with the most common
devices, such as smartphones, tablets, and wearables.
Test have been implemented using the \emph{Kotest} framework, which is a flexible and comprehensive testing framework for Kotlin
with multiplatform support.

\paragraph{Unit Tests}
Focused on individual units or components within a software system, unit testing serves to validate their functionality
according to requirements.
Typically conducted by developers as the initial testing phase, it involves automation and occurs each time modifications
are made to the source code to prevent disruption of existing features.
These tests are engineered to verify the smallest units of code, such as individual functions or methods, in isolation
from the broader system context.

\paragraph{Integration Tests}
Integration testing is a software testing methodology used to evaluate the functionality of combined units of code.
It serves to expose faults in the interaction between integrated units, ensuring that they function as expected.
This type of testing is particularly useful in the context of the \ac{dsl} as it allows the verification of the correct
interactions of the different parts of the system.

\subsection{Continuous Integration and Deployment}
\label{subsec:continuous-integration-and-deployment}
\ac{cicd} are software development practices that aim to automate and streamline the process of delivering high-quality software.
\ac{ci} is a development practice where developers frequently integrate their code changes into a shared repository.
Each integration triggers an automated build process, during which the code is compiled, tested, and verified against a
set of predefined criteria.

The primary goals of \ac{ci} are to detect integration errors early, ensure that the codebase remains functional,
and promote collaboration among team members.
\ac{ci} key features include:
    i) automated builds, automatically triggered by committed code changes;
    ii) automated testing, run automatically during the build process;
    iii) immediate feedback, provided to developers regarding the status of their code changes, allowing to address issues promptly;
    iv) version control integration, enabling seamless integration with code repositories.

\ac{cd} extends the principles of \ac{ci} by automating the deployment process after successful integration and testing.
It involves automatically deploying validated code changes to production or staging environments, eliminating manual
intervention and reducing the time between code changes and their availability to users.
\ac{cd} helps streamline the release process, reduce deployment errors, and enable rapid and reliable software delivery.
\ac{cd} key features include:
    i) automated deployment, Deployments to production or staging environments are automated, ensuring consistency and reliability;
    ii) continuous monitoring, integrated into CD pipelines to track application performance and detect issues in real-time;
    iii) rollback mechanisms, in case of deployment failures;
    iv) environment provisioning, pipelines often include steps for provisioning and configuring target environments as part of the deployment process.

\section{Alchemist Simulations}
\label{sec:alchemist-simulations}


%examples
\section{Performance / Comparison}
\label{sec:performance-/-comparison}
To have a clear understanding of the performances of the new implementation, it is necessary to compare it with the other
\emph{ScaFi} and \emph{Protelis}' incarnations.
The comparison is made by running the same simulations on each incarnation and comparing the results.
The simulations are run on the same machine to ensure that the comparison is fair and that the differences are due to the
implementation and not to the hardware.

The performance of the new language has been evaluated through the implementation of 5 types of tests:
\begin{enumerate}
    \item Simple \textbf{state change} of the device, to represent the variation over time of the field;
    \item A \textbf{counter of the neighbours}, to represent the variation of the space;
    \item A \textbf{gradient}, which is a particular case of space-time variation, in which the value of a node is a
        function of the distance from a node considered as a source;
    \item A \textbf{channel with obstacles}, to represent the presence of obstacles in space that influence the communication between nodes;
    \item Simple \textbf{branching} operations, as it has been noticed that branching could be one of the most expensive operations in terms of execution time.
\end{enumerate}

Each test has been run with the same parameters in the three different incarnations with three different simulated times
inside the \emph{Alchemist} simulator, and the results have been analysed and will be further discussed in this section.

\paragraph{Machine Specifications}
The results that will be presented have been obtained by running the simulations on a machine with the following specifications:
\begin{itemize}
    \item \textbf{Processor}: Intel(R) Core(TM) i9-14900KF;
    \item \textbf{RAM}: 64GB 4800mhz;
    \item \textbf{OS}: Linux Manjaro;
\end{itemize}

Other runs have been made on a different machine to ensure that the results are consistent across different hardware,
the machine used is the same as the tests one.

\paragraph{Foreword}
During the evolution of this thesis, it has been noticed that the current implementation of the alignment in \emph{Collektive}
may not be the optimal, as explained in \ref{sec:alignment}, and therefore the results could be influenced by this.
A way to implement a faster check on the alignment has been found, and it will be implemented in the future to have a more accurate comparison.

\paragraph{Field Evolution}
The first test has been implemented using the \texttt{repeat} construct.
It doesn't need any particular setup, as it is a simple state change of the device.

From the results, it is possible to see that the \emph{Protelis} implementation is faster than the \emph{Collektive} one,
which in turn is faster than the \emph{ScaFi} implementation.
%todo

\paragraph{Neighbour Counter}

\paragraph{Gradient}

\paragraph{Channel with Obstacles}

\paragraph{Branching}

\section{Discussion}

